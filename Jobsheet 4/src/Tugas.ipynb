{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomor 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      female       0.96      0.99      0.98       297\n",
      "        male       0.99      0.97      0.98       337\n",
      "\n",
      "    accuracy                           0.98       634\n",
      "   macro avg       0.98      0.98      0.98       634\n",
      "weighted avg       0.98      0.98      0.98       634\n",
      "\n",
      "Akurasi: 0.9763406940063092\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "data = pd.read_csv('../docs/voice.csv')\n",
    "\n",
    "X = data.drop('label', axis=1)  # Asumsi 'label' adalah target\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm_model = SVC(kernel='linear')  # Kamu bisa coba kernel lain seperti 'rbf', 'poly'\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Akurasi:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomor 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       965\n",
      "           1       0.96      0.92      0.94       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Akurasi: 0.9838565022421525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "data = pd.read_csv('../docs/spam.csv', encoding='latin-1')\n",
    "data = data[['v1', 'v2']]  # Asumsi 'v1' adalah label dan 'v2' adalah pesan teks\n",
    "data.columns = ['label', 'text']\n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "X = data['text']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "\n",
    "y_pred = nb_model.predict(X_test_vec)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('Akurasi:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomor 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.75      0.86       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.96      1115\n",
      "\n",
      "Akurasi: 0.9668161434977578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "nb_model_tfidf = MultinomialNB()\n",
    "nb_model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_pred_tfidf = nb_model_tfidf.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, y_pred_tfidf))\n",
    "print('Akurasi:', accuracy_score(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan hasil evaluasi, model Multinomial Naive Bayes dengan CountVectorizer memberikan performa yang lebih baik secara keseluruhan, terutama dalam hal akurasi, recall, dan F1-Score. Meski precision untuk label spam sedikit lebih rendah, model dengan CountVectorizer lebih sensitif dan seimbang dalam mendeteksi pesan spam. Oleh karena itu, CountVectorizer lebih efektif untuk klasifikasi data dalam kasus ini dibandingkan TF-IDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
