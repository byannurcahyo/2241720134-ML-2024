{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KlgyBuMtSJ-nyo6glVirnY3HM1bsiH_Q",
      "authorship_tag": "ABX9TyMIWCH7n4hvy0XYxXd07flv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byannurcahyo/2241720134-ML-2024/blob/main/Feature%20Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum Mata Kuliah Machine Learning** :\n",
        "## Byan Nur Cahyo / 2241720134 / TI-3D"
      ],
      "metadata": {
        "id": "zesWGpOJlpSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum** :"
      ],
      "metadata": {
        "id": "mhRV9Fz9mWne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Implementasi Normalisasi"
      ],
      "metadata": {
        "id": "eCU__MlRmeaL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH1GHXmOZJfE",
        "outputId": "9d9a6438-4c73-4c03-aabf-2020c8ee4422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.16666666666666666, 0.3333333333333333, 0.6666666666666666, 1.0]\n"
          ]
        }
      ],
      "source": [
        "def norm_data(data):\n",
        "  '''\n",
        "  Melakukan normalisasi data.\n",
        "\n",
        "  Parameters:\n",
        "      data (list) : Data yang akan dinormalisasi\n",
        "\n",
        "    Returns:\n",
        "      data (list) : Data hasil normalisasi\n",
        "  '''\n",
        "  data_max = max(data)\n",
        "  data_min = min(data)\n",
        "  data_len = len(data)\n",
        "\n",
        "  for i in range(0, data_len):\n",
        "    data[i] = (data[i] - data_min) / (data_max - data_min)\n",
        "  return data\n",
        "\n",
        "#contoh penggunaan\n",
        "data = [10, 11, 12, 14, 16]\n",
        "n_data = norm_data(data)\n",
        "print(n_data)\n",
        "#output : [0.0, 0.25, 0.5, 0.75, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "np.set_printoptions(precision=6)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "data = [\n",
        "    [100, 0.0001],\n",
        "    [50, 0.05],\n",
        "    [30, 0.003]\n",
        "]\n",
        "\n",
        "data = np.array(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled = scaler.fit_transform(data)\n",
        "print('Data Normalisasi')\n",
        "print(scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veK6Z9g1c7VA",
        "outputId": "e1987cf9-c8f8-4f84-de9c-c44f59652fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Normalisasi\n",
            "[[1.       0.      ]\n",
            " [0.285714 1.      ]\n",
            " [0.       0.058116]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Implementasi Standard"
      ],
      "metadata": {
        "id": "QCg8C4GxmzI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "np.set_printoptions(precision=6)\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "data = [\n",
        "    [100, 0.0001],\n",
        "    [50, 0.05],\n",
        "    [30, 0.003]\n",
        "]\n",
        "\n",
        "data = np.array(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "\n",
        "scaler =StandardScaler()\n",
        "scaled = scaler.fit_transform(data)\n",
        "print('Data Standarisasi')\n",
        "print(scaled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvrUBRbzd2u7",
        "outputId": "f6372415-d443-4630-941b-78803ef315a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[[100.       0.0001]\n",
            " [ 50.       0.05  ]\n",
            " [ 30.       0.003 ]]\n",
            "Data Standarisasi\n",
            "[[ 1.358732 -0.76956 ]\n",
            " [-0.339683  1.412317]\n",
            " [-1.019049 -0.642757]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Implementasi Ordinal Encoding"
      ],
      "metadata": {
        "id": "cwl62C-WnEzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "oe = OrdinalEncoder()\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang'],\n",
        "]\n",
        "\n",
        "transform_oe = oe.fit_transform(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "print('Data Transformasi Ordinal Encoder')\n",
        "print(transform_oe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOsBuNSAeOlh",
        "outputId": "568a3c85-27ce-4c1b-82f2-3505f1866883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi Ordinal Encoder\n",
            "[[2.]\n",
            " [0.]\n",
            " [1.]\n",
            " [3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Implementasi One-Hot Encoding"
      ],
      "metadata": {
        "id": "nes0933lnLWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang'],\n",
        "]\n",
        "\n",
        "transform_ohe = ohe.fit_transform(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "print('Data Transformasi One-Hot Encoding')\n",
        "print(transform_ohe.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MExdUzLe0Zc",
        "outputId": "f89745f2-4ddd-402d-8819-d203a51d6c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One-Hot Encoding\n",
            "[[0. 0. 1. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Implementasi Dummy Variable Encoding"
      ],
      "metadata": {
        "id": "ZJ8nH6pLnjbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "de = OneHotEncoder(drop='first')\n",
        "\n",
        "data = [\n",
        "    ['Politeknik Negeri Malang'],\n",
        "    ['Politeknik Elektronika Negeri Surabaya'],\n",
        "    ['Politeknik Negeri Jakarta'],\n",
        "    ['Politeknik Negeri Semarang'],\n",
        "]\n",
        "\n",
        "transform_de = de.fit_transform(data)\n",
        "print('Data Asli')\n",
        "print(data)\n",
        "print('Data Transformasi One-Hot Encoding')\n",
        "print(transform_de.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0OGWXepfLmV",
        "outputId": "87896f07-b57f-4550-d7f0-1654701d3a2c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Asli\n",
            "[['Politeknik Negeri Malang'], ['Politeknik Elektronika Negeri Surabaya'], ['Politeknik Negeri Jakarta'], ['Politeknik Negeri Semarang']]\n",
            "Data Transformasi One-Hot Encoding\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Studi Kasus Ekstraksi Fitur dari Data Teks"
      ],
      "metadata": {
        "id": "CQQH40Hwnt1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'The house had a tiny little mouse',\n",
        "    'The cat saw the mouse',\n",
        "    'The mouse ran away from the house',\n",
        "    'The cat finally ate the mouse',\n",
        "    'The end of the mouse story'\n",
        "]\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "print('Hasil TF-IDF')\n",
        "print(resp)\n",
        "\n",
        "print('Hasil Token')\n",
        "print(vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moSOgY68grvf",
        "outputId": "00ea0449-ec8c-4bde-a8c9-f3f1cae11d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil TF-IDF\n",
            "  (0, 7)\t0.2808823162882302\n",
            "  (0, 6)\t0.5894630806320427\n",
            "  (0, 11)\t0.5894630806320427\n",
            "  (0, 5)\t0.47557510189256375\n",
            "  (1, 9)\t0.7297183669435993\n",
            "  (1, 2)\t0.5887321837696324\n",
            "  (1, 7)\t0.3477147117091919\n",
            "  (2, 1)\t0.5894630806320427\n",
            "  (2, 8)\t0.5894630806320427\n",
            "  (2, 7)\t0.2808823162882302\n",
            "  (2, 5)\t0.47557510189256375\n",
            "  (3, 0)\t0.5894630806320427\n",
            "  (3, 4)\t0.5894630806320427\n",
            "  (3, 2)\t0.47557510189256375\n",
            "  (3, 7)\t0.2808823162882302\n",
            "  (4, 10)\t0.6700917930430479\n",
            "  (4, 3)\t0.6700917930430479\n",
            "  (4, 7)\t0.3193023297639811\n",
            "Hasil Token\n",
            "['ate' 'away' 'cat' 'end' 'finally' 'house' 'little' 'mouse' 'ran' 'saw'\n",
            " 'story' 'tiny']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas Praktikum** :"
      ],
      "metadata": {
        "id": "kJy2ZXy-n6Z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/corpus.txt'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    corpus = file.readlines()\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "resp = vect.fit_transform(corpus)\n",
        "\n",
        "print('Hasil TF-IDF')\n",
        "print(resp)\n",
        "\n",
        "print('Hasil Token')\n",
        "print(vect.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8UxW2mNhrMe",
        "outputId": "7b860960-e00d-4c82-8004-f41bcec68e3e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Hasil TF-IDF\n",
            "  (0, 3)\t1.0\n",
            "  (1, 8)\t0.31257907911644855\n",
            "  (1, 7)\t0.579262311604141\n",
            "  (1, 12)\t0.579262311604141\n",
            "  (1, 6)\t0.48083746527154797\n",
            "  (2, 10)\t0.7106281860049563\n",
            "  (2, 2)\t0.5898824226331707\n",
            "  (2, 8)\t0.3834661767662525\n",
            "  (3, 1)\t0.579262311604141\n",
            "  (3, 9)\t0.579262311604141\n",
            "  (3, 8)\t0.31257907911644855\n",
            "  (3, 6)\t0.48083746527154797\n",
            "  (4, 0)\t0.579262311604141\n",
            "  (4, 5)\t0.579262311604141\n",
            "  (4, 2)\t0.48083746527154797\n",
            "  (4, 8)\t0.31257907911644855\n",
            "  (5, 11)\t0.6606476647333884\n",
            "  (5, 4)\t0.6606476647333884\n",
            "  (5, 8)\t0.3564958992255601\n",
            "Hasil Token\n",
            "['ate' 'away' 'cat' 'corpus' 'end' 'finally' 'house' 'little' 'mouse'\n",
            " 'ran' 'saw' 'story' 'tiny']\n"
          ]
        }
      ]
    }
  ]
}